"""Training utilities for lead scoring models."""

from __future__ import annotations

from pathlib import Path
from typing import Dict
import pickle
from math import sqrt

import numpy as np
import pandas as pd
from sklearn.metrics import (
    log_loss,
    roc_auc_score,
    mean_absolute_error,
    mean_squared_error,
    mean_absolute_percentage_error,
)

import tensorflow as tf
from tensorflow.keras import layers, Model
from statsmodels.tsa.arima.model import ARIMA
from prophet import Prophet

try:  # Optional dependency
    from pmdarima import auto_arima as _auto_arima
except Exception as _exc_pmdarima:  # pragma: no cover - optional
    _auto_arima = None


# ---------------------------------------------------------------------------
# Main training function
# ---------------------------------------------------------------------------

def train_lstm_lead(cfg: Dict[str, Dict]):
    """Train a simple MLP/LSTM model on the preprocessed lead scoring dataset.

    Parameters
    ----------
    cfg: dict
        Configuration dictionary containing ``lstm_params`` and ``output_dir``.
    """

    lead_cfg = cfg.get("lead_scoring", {})
    out_dir = Path(lead_cfg.get("output_dir", cfg.get("output_dir", ".")))

    # ------------------------------------------------------------------
    # Load train/validation sets generated by ``preprocess_lead_scoring``
    # ------------------------------------------------------------------
    X_train = pd.read_csv(out_dir / "X_train.csv")
    y_train = pd.read_csv(out_dir / "y_train.csv").squeeze()
    X_val = pd.read_csv(out_dir / "X_val.csv")
    y_val = pd.read_csv(out_dir / "y_val.csv").squeeze()

    # Convert to ``np.ndarray`` and ensure correct dtypes
    X_train = np.asarray(X_train, dtype=float)
    X_val = np.asarray(X_val, dtype=float)
    y_train = np.asarray(y_train, dtype=int).ravel()
    y_val = np.asarray(y_val, dtype=int).ravel()

    # ------------------------------------------------------------------
    # Model definition
    # ------------------------------------------------------------------
    inp = layers.Input(shape=(X_train.shape[1],), name="features")
    x = layers.Dense(256, activation="relu")(inp)
    x = layers.Dropout(0.3)(x)
    x = layers.Dense(128, activation="relu")(x)
    x = layers.Dropout(0.3)(x)
    out = layers.Dense(1, activation="sigmoid")(x)
    model_lstm = Model(inputs=inp, outputs=out)
    model_lstm.compile(
        optimizer=tf.keras.optimizers.Adam(
            learning_rate=cfg["lstm_params"]["learning_rate"]
        ),
        loss="binary_crossentropy",
        metrics=["AUC", "accuracy"],
    )

    # ------------------------------------------------------------------
    # Training
    # ------------------------------------------------------------------
    model_lstm.fit(
        X_train,
        y_train,
        validation_data=(X_val, y_val),
        batch_size=cfg["lstm_params"]["batch_size"],
        epochs=cfg["lstm_params"]["epochs"],
        callbacks=[
            tf.keras.callbacks.EarlyStopping(
                monitor="val_loss",
                patience=cfg["lstm_params"]["patience"],
                restore_best_weights=True,
            )
        ],
        verbose=cfg["lstm_params"].get("verbose", 1),
    )

    # ------------------------------------------------------------------
    # Save trained model
    # ------------------------------------------------------------------
    model_path = Path(cfg.get("output_dir", ".")) / "models" / "lead_lstm.h5"
    model_path.parent.mkdir(parents=True, exist_ok=True)
    model_lstm.save(model_path)

    # ------------------------------------------------------------------
    # Validation metrics
    # ------------------------------------------------------------------
    val_preds = model_lstm.predict(X_val).ravel()
    logloss_val = log_loss(y_val, val_preds)
    auc_val = roc_auc_score(y_val, val_preds)
    print(f"Validation log loss: {logloss_val:.4f}, AUC: {auc_val:.4f}")

    return model_lstm


def train_arima_conv_rate(cfg: Dict[str, Dict]):
    """Train an ARIMA model on the conversion rate time series.

    Parameters
    ----------
    cfg : dict
        Configuration dictionary containing ``lead_scoring`` settings.
    """

    lead_cfg = cfg.get("lead_scoring", {})
    out_dir = Path(lead_cfg.get("output_dir", cfg.get("output_dir", ".")))

    # ------------------------------------------------------------------
    # Load conversion rate series generated by ``preprocess_lead_scoring``
    # ------------------------------------------------------------------
    ts_conv_rate_train = (
        pd.read_csv(out_dir / "ts_conv_rate_train.csv", index_col=0, parse_dates=True)[
            "conv_rate"
        ]
    )
    ts_conv_rate_test = (
        pd.read_csv(out_dir / "ts_conv_rate_test.csv", index_col=0, parse_dates=True)[
            "conv_rate"
        ]
    )

    # Determine ARIMA order either from config or via automatic search
    order = lead_cfg.get("arima_order")
    if order is None:
        if _auto_arima is None:
            raise ImportError(
                "pmdarima is required for automatic ARIMA order search"
            ) from _exc_pmdarima
        auto_model = _auto_arima(
            ts_conv_rate_train,
            seasonal=False,
            error_action="ignore",
            suppress_warnings=True,
        )
        order = auto_model.order

    arima_model = ARIMA(ts_conv_rate_train, order=tuple(order))
    fitted_arima = arima_model.fit()

    h = len(ts_conv_rate_test)
    forecast = fitted_arima.get_forecast(steps=h)
    arima_pred = forecast.predicted_mean

    mae = mean_absolute_error(ts_conv_rate_test, arima_pred)
    rmse = sqrt(mean_squared_error(ts_conv_rate_test, arima_pred))
    mape = mean_absolute_percentage_error(ts_conv_rate_test, arima_pred)

    model_path = Path(cfg.get("output_dir", ".")) / "models" / "arima_conv_rate.pkl"
    model_path.parent.mkdir(parents=True, exist_ok=True)
    with open(model_path, "wb") as fh:
        pickle.dump(fitted_arima, fh)

    return fitted_arima, {"mae": mae, "rmse": rmse, "mape": mape}


def train_prophet_conv_rate(cfg: Dict[str, Dict]):
    """Train a Prophet model on the aggregated conversion rate time series.

    Parameters
    ----------
    cfg : dict
        Configuration dictionary containing ``lead_scoring`` settings.
    """

    lead_cfg = cfg.get("lead_scoring", {})
    out_dir = Path(lead_cfg.get("output_dir", cfg.get("output_dir", ".")))

    # ------------------------------------------------------------------
    # Load Prophet training DataFrame and test series generated by
    # ``preprocess_lead_scoring``
    # ------------------------------------------------------------------
    df_prophet_train = pd.read_csv(out_dir / "df_prophet_train.csv", parse_dates=["ds"])
    ts_conv_rate_test = (
        pd.read_csv(out_dir / "ts_conv_rate_test.csv", index_col=0, parse_dates=True)[
            "conv_rate"
        ]
    )

    prophet_params = lead_cfg.get("prophet_params", {})
    model_prophet = Prophet(**prophet_params)
    model_prophet.fit(df_prophet_train)

    future = model_prophet.make_future_dataframe(
        periods=lead_cfg.get("prophet_forecast_periods", len(ts_conv_rate_test)),
        freq="M",
    )
    forecast = model_prophet.predict(future)
    prophet_pred = forecast.set_index("ds")["yhat"].loc[ts_conv_rate_test.index]

    mae = mean_absolute_error(ts_conv_rate_test, prophet_pred)
    rmse = sqrt(mean_squared_error(ts_conv_rate_test, prophet_pred))
    mape = mean_absolute_percentage_error(ts_conv_rate_test, prophet_pred)

    model_path = Path(cfg.get("output_dir", ".")) / "models" / "prophet_conv_rate.pkl"
    model_path.parent.mkdir(parents=True, exist_ok=True)
    with open(model_path, "wb") as fh:
        pickle.dump(model_prophet, fh)

    return model_prophet, {"mae": mae, "rmse": rmse, "mape": mape}


__all__ = ["train_lstm_lead", "train_arima_conv_rate", "train_prophet_conv_rate"]

