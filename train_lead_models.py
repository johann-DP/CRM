"""Training utilities for lead scoring models."""

from __future__ import annotations

from pathlib import Path
from typing import Dict

import numpy as np
import pandas as pd
from sklearn.metrics import log_loss, roc_auc_score

import tensorflow as tf
from tensorflow.keras import layers, Model


# ---------------------------------------------------------------------------
# Main training function
# ---------------------------------------------------------------------------

def train_lstm_lead(cfg: Dict[str, Dict]):
    """Train a simple MLP/LSTM model on the preprocessed lead scoring dataset.

    Parameters
    ----------
    cfg: dict
        Configuration dictionary containing ``lstm_params`` and ``output_dir``.
    """

    lead_cfg = cfg.get("lead_scoring", {})
    out_dir = Path(lead_cfg.get("output_dir", cfg.get("output_dir", ".")))

    # ------------------------------------------------------------------
    # Load train/validation sets generated by ``preprocess_lead_scoring``
    # ------------------------------------------------------------------
    X_train = pd.read_csv(out_dir / "X_train.csv")
    y_train = pd.read_csv(out_dir / "y_train.csv").squeeze()
    X_val = pd.read_csv(out_dir / "X_val.csv")
    y_val = pd.read_csv(out_dir / "y_val.csv").squeeze()

    # Convert to ``np.ndarray`` and ensure correct dtypes
    X_train = np.asarray(X_train, dtype=float)
    X_val = np.asarray(X_val, dtype=float)
    y_train = np.asarray(y_train, dtype=int).ravel()
    y_val = np.asarray(y_val, dtype=int).ravel()

    # ------------------------------------------------------------------
    # Model definition
    # ------------------------------------------------------------------
    inp = layers.Input(shape=(X_train.shape[1],), name="features")
    x = layers.Dense(256, activation="relu")(inp)
    x = layers.Dropout(0.3)(x)
    x = layers.Dense(128, activation="relu")(x)
    x = layers.Dropout(0.3)(x)
    out = layers.Dense(1, activation="sigmoid")(x)
    model_lstm = Model(inputs=inp, outputs=out)
    model_lstm.compile(
        optimizer=tf.keras.optimizers.Adam(
            learning_rate=cfg["lstm_params"]["learning_rate"]
        ),
        loss="binary_crossentropy",
        metrics=["AUC", "accuracy"],
    )

    # ------------------------------------------------------------------
    # Training
    # ------------------------------------------------------------------
    model_lstm.fit(
        X_train,
        y_train,
        validation_data=(X_val, y_val),
        batch_size=cfg["lstm_params"]["batch_size"],
        epochs=cfg["lstm_params"]["epochs"],
        callbacks=[
            tf.keras.callbacks.EarlyStopping(
                monitor="val_loss",
                patience=cfg["lstm_params"]["patience"],
                restore_best_weights=True,
            )
        ],
        verbose=cfg["lstm_params"].get("verbose", 1),
    )

    # ------------------------------------------------------------------
    # Save trained model
    # ------------------------------------------------------------------
    model_path = Path(cfg.get("output_dir", ".")) / "models" / "lead_lstm.h5"
    model_path.parent.mkdir(parents=True, exist_ok=True)
    model_lstm.save(model_path)

    # ------------------------------------------------------------------
    # Validation metrics
    # ------------------------------------------------------------------
    val_preds = model_lstm.predict(X_val).ravel()
    logloss_val = log_loss(y_val, val_preds)
    auc_val = roc_auc_score(y_val, val_preds)
    print(f"Validation log loss: {logloss_val:.4f}, AUC: {auc_val:.4f}")

    return model_lstm


__all__ = ["train_lstm_lead"]
